# data file from db export
path_in <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/01_dbExport/out/"
dat_ifile <- "apress_data.dat"
# output
odir <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/02_adjust_timesteps/out/"
??read.tab
?read.table
nadata <- -9999
dat <- read.table(paste(path_in, dat_ifile, sep="/"), header=F, sep="\t", skip=1, na.string=nadata)
View(dat)
header_dat <- readLines(dat_ifile, n=1)
names_col <- strsplit(header_dat, "\t")[[1]][-1]
header_dat <- readLines(paste(path_in, dat_ifile, sep="/"), n=1)
names_col <- strsplit(header_dat, "\t")[[1]][-1]
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
library(xts)
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
dat_daily <- apply.daily(dat_xts, mean, na.rm=T)
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
?write.table
write.zoo(dat_daily, paste(odir, dat_ifile, sep="/"), append=T, col.names=F, quote=F, sep="\t", na=nadata)
?write.zoo
write.zoo(dat_daily, paste(odir, dat_ifile, sep="/"), append=T, col.names=F, quote=F, sep="\t", na=as.character(nadata))
# MySQL settings #
user <- "tobias"
password <- "tobias"
dbname <- "jaguaribe_gages" # name of the empty database, should be created beforehand
host <- "localhost"
# open MySQL connection (needs to be created beforehand and should be empty)
con <- dbConnect(MySQL(), user=user, password=password,
dbname=dbname, host=host, client.flag = CLIENT_MULTI_STATEMENTS)
# start GRASS session
initGRASS( gisBase="/opt/grass",
home=tempdir(),
location="Ceara",
mapset="Reservoirs_drainage",
gisDbase="/home/tobias/Promotion/Modellierung/grassdata",
override=TRUE)
# vector file with station locations
gages_vect <- "cli_gages"
# vector of catchment in GRASS
catch_vect <- "catchment@ECHSE_topocatch"
# gages have to be within that distance around the catchment (in GRASS region units)
dist_lim <- 100000
# no data value in output
nodata= -9999
# variables
pars= data.frame(stringsAsFactors=FALSE,
#                 id_db=     c("precipitation", "rel_hum", "temp_mean", "windspeed", "sunshine"),
#                 id_export= c("precip", "rhumid", "temper", "windsp", "sunshine")
id_db=     c("pressure"),
id_export= c("apress")
)
# define time period for time series extraction
start_date <- "1999-01-01 00:00:00"
end_date <- "2013-12-31 00:00:00"
# temporal resolution of data (flag in db)
resol <- 4
# maximum fraction of NA data allowed in time period
na_frac <- 1/3
# output directory
odir= "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/01_dbExport/out/"
### CALCULATIONS ###
# helper function
stat_identify <- function(x,gag=gages,cat=catch,dist=dist_lim) {
index <- which(gag@data$code == x)
return(gWithinDistance(gag[index,], cat, dist=dist))
}
# load gages and catchment from GRASS
gages <- readVECT6(gages_vect)
catch <- readVECT6(catch_vect)
# Loop over variables
for (k in 1:nrow(pars)) {
# get data filtered by resolution flag and defined time period
q= paste0("SELECT gage_code,date,",pars$id_db[k], " FROM clim_ts WHERE ",
"resolution=", resol, " AND ",
"(date BETWEEN '",start_date,"' AND '",end_date, "')")
db_dat <- dbGetQuery(con, q)
# re-order data
dat_mat <- tapply(db_dat[[3]], list(date=db_dat$date, station=db_dat$gage_code), function(x) x)
# keep only data for station within defined distance around catchment
stat <- colnames(dat_mat)
stat_keep <- lapply(stat, stat_identify)
dat_mat <- dat_mat[,unlist(stat_keep)]
# keep only those stations and data which have enough non-NA data
stat_keep <- apply(dat_mat, 2, function(x, na_f=na_frac) return(length(which(is.na(x))) < na_f * length(x)))
dat_mat <- dat_mat[, stat_keep]
print(paste0("Found ",ncol(dat_mat)," stations within given distance around the catchment with sufficient non-NA data for variable '",
pars$id_export[k],"'"))
# replace NA value by specified value
dat_mat[which(is.na(dat_mat))] <- nodata
# set up station data.frame for export
rows <- gages@data$code %in% as.integer(colnames(dat_mat))
locs_out <- data.frame(id=gages@data$code[rows],
x=coordinates(gages[rows,])[,1],
y=coordinates(gages[rows,])[,2],
z=gages@data$alt[rows],
name=gages@data$name[rows])
locs_out$z[which(is.na(locs_out$z))] <- nodata
write.table(locs_out, paste0(odir,"/",pars$id_export[k],"_locs.dat"), quote=F, sep="\t", row.names=F)
# data output
ofile <- paste0(odir,"/",pars$id_export[k],"_data.dat")
write(c("end_of_interval", colnames(dat_mat)), ofile, sep="\t", ncolumns=ncol(dat_mat)+1)
write.table(dat_mat, ofile, col.names=F, sep="\t", quote=F, append=T)
} # loop over variables
library(xts)
# data file from db export
path_in <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/01_dbExport/out/"
dat_ifile <- "apress_data.dat"
# output
odir <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/02_adjust_timesteps/out/"
nadata <- -9999
# read data
dat <- read.table(paste(path_in, dat_ifile, sep="/"), header=F, sep="\t", skip=1, na.string=nadata)
header_dat <- readLines(paste(path_in, dat_ifile, sep="/"), n=1)
# create xts object
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
# calculate simple mean value from sub-daily values
dat_daily <- apply.daily(dat_xts, mean, na.rm=T)
# write output
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.zoo(dat_daily, paste(odir, dat_ifile, sep="/"), append=T, col.names=F, quote=F, sep="\t", na=as.character(nadata))
str(dat_xts)
str(dat_daily)
?apply.daily
View(dat_xts)
View(dat_xts)
View(dat_daily)
index(dat_daily)
format(index(dat_daily), "%Y-%m-%d 00:00:00")
as.POSIXct(format(index(dat_daily), "%Y-%m-%d 00:00:00"), tz="Fortaleza/Brazil")
index(dat_daily) <- as.POSIXct(format(index(dat_daily), "%Y-%m-%d 00:00:00"), tz="Fortaleza/Brazil")
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.zoo(dat_daily, paste(odir, dat_ifile, sep="/"), append=T, col.names=F, quote=F, sep="\t", na=as.character(nadata))
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.table(dat_daily, paste(odir, dat_ifile, sep="/"), sep="\t", quote=F, col.names=F, row.names=format(index(dat_daily), '%Y-%m-%d %H:%M:%S'), append=T, na=as.character(nadata))
# take data from db export and adjust temporal resolution
library(xts)
# data file from db export
path_in <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/01_dbExport/out/"
dat_ifile <- "apress_data.dat"
# output
odir <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/02_adjust_timesteps/out/"
nadata <- -9999
# read data
dat <- read.table(paste(path_in, dat_ifile, sep="/"), header=F, sep="\t", skip=1, na.string=nadata)
header_dat <- readLines(paste(path_in, dat_ifile, sep="/"), n=1)
# create xts object
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
# calculate simple mean value from sub-daily values
dat_daily <- apply.daily(dat_xts, mean, na.rm=T)
# time set to 18:00:00 as it alway was the last time for every in dat_xts -> set back to 00:00:00
index(dat_daily) <- as.POSIXct(format(index(dat_daily), "%Y-%m-%d 00:00:00"), tz="Fortaleza/Brazil")
# write output
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.table(dat_daily, paste(odir, dat_ifile, sep="/"), sep="\t", quote=F, col.names=F, row.names=format(index(dat_daily), '%Y-%m-%d %H:%M:%S'), append=T, na=as.character(nadata))
# take data from db export and adjust temporal resolution
library(xts)
# data file from db export
path_in <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/01_dbExport/out/"
dat_ifile <- "apress_data.dat"
# output
odir <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/02_adjust_timesteps/out/"
nadata <- -9999
# read data
dat <- read.table(paste(path_in, dat_ifile, sep="/"), header=F, sep="\t", skip=1, na.string=nadata)
header_dat <- readLines(paste(path_in, dat_ifile, sep="/"), n=1)
# create xts object
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
# calculate simple mean value from sub-daily values
dat_daily <- apply.daily(dat_xts, mean, na.rm=T)
# time set to 18:00:00 as it alway was the last time for every in dat_xts -> set back to 00:00:00
index(dat_daily) <- as.POSIXct(format(index(dat_daily), "%Y-%m-%d 00:00:00"), tz="Fortaleza/Brazil")
# write output
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.table(dat_daily, paste(odir, dat_ifile, sep="/"), sep="\t", quote=F, col.names=F, row.names=format(index(dat_daily), '%Y-%m-%d %H:%M:%S'), append=T, na=as.character(nadata))
# take data from db export and adjust temporal resolution
library(xts)
# data file from db export
path_in <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/01_dbExport/out/"
dat_ifile <- "apress_data.dat"
# output
odir <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/02_adjust_timesteps/out/"
nadata <- -9999
# read data
dat <- read.table(paste(path_in, dat_ifile, sep="/"), header=F, sep="\t", skip=1, na.string=nadata)
header_dat <- readLines(paste(path_in, dat_ifile, sep="/"), n=1)
# create xts object
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
# calculate simple mean value from sub-daily values
dat_daily <- apply.daily(dat_xts, mean, na.rm=T)
# time set to 18:00:00 as it alway was the last time for every in dat_xts -> set back to 00:00:00
index(dat_daily) <- as.POSIXct(format(index(dat_daily), "%Y-%m-%d 00:00:00"), tz="Fortaleza/Brazil")
# write output
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.table(dat_daily, paste(odir, dat_ifile, sep="/"), sep="\t", quote=F, col.names=F, row.names=format(index(dat_daily), '%Y-%m-%d %H:%M:%S'), append=T, na=as.character(nadata))
library(xts)
# data file from db export
path_in <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/01_dbExport/out/"
dat_ifile <- "apress_data.dat"
# output
odir <- "/home/tobias/Promotion/Modellierung/ECHSE/preprocessing/03_forcings/meteo/02_adjust_timesteps/out/"
nadata <- -9999
# read data
dat <- read.table(paste(path_in, dat_ifile, sep="/"), header=F, sep="\t", skip=1, na.string=nadata)
header_dat <- readLines(paste(path_in, dat_ifile, sep="/"), n=1)
# create xts object
dat_xts <- xts(dat[,-1], as.POSIXct(dat[,1], tz="Fortaleza/Brazil"))
# calculate simple mean value from sub-daily values
dat_daily <- apply.daily(dat_xts, mean, na.rm=T)
# time set to 18:00:00 as it alway was the last time for every in dat_xts -> set back to 00:00:00
index(dat_daily) <- as.POSIXct(format(index(dat_daily), "%Y-%m-%d 00:00:00"), tz="Fortaleza/Brazil")
# write output
writeLines(text=header_dat, con=paste(odir, dat_ifile, sep="/"))
write.table(dat_daily, paste(odir, dat_ifile, sep="/"), sep="\t", quote=F, col.names=F, row.names=format(index(dat_daily), '%Y-%m-%d %H:%M:%S'), append=T, na=as.character(nadata))
